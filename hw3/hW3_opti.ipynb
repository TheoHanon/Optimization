{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding PCA to fasten the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from derivative import *\n",
    "from HW3_B2 import *\n",
    "from HW3_B4 import several_newton\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import solve\n",
    "from progress.bar import Bar\n",
    "from alive_progress import alive_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pca(vectors_A, vectors_B, n):\n",
    "    # Combine the two arrays into a single array for PCA\n",
    "    combined_vectors = np.concatenate((vectors_A, vectors_B))\n",
    "    pca = PCA(n_components=n)\n",
    "    # Fit and transform the combined vectors\n",
    "    transformed_vectors = pca.fit_transform(combined_vectors)\n",
    "    # Split the transformed data back into vectors_A and vectors_B\n",
    "    new_vectors_A = transformed_vectors[:len(vectors_A)]\n",
    "    new_vectors_B = transformed_vectors[len(vectors_A):]\n",
    "\n",
    "    return new_vectors_A, new_vectors_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to perform the optimization\n",
    "def short_step_method(class_A, class_B, lambda_param, nu, epsilon):\n",
    "\n",
    "    nA, n = class_A.vectors.shape\n",
    "    nB = class_B.vectors.shape[0]\n",
    "\n",
    "    C = c_coeff(n, nA, nB, lambda_param)\n",
    "\n",
    "    tau = 1/4\n",
    "    theta = 1/(16*np.sqrt(nu))\n",
    "\n",
    "    h, c, s, t, v, mu = init(class_A, class_B)\n",
    "    mu_final = epsilon * (1 - tau) / nu\n",
    "\n",
    "    ite = 0\n",
    "    with alive_bar(10000) as bar:\n",
    "        while mu > mu_final and ite < 10000:\n",
    "            mu *= (1 - theta)\n",
    "            step = newton_step(h, c, s, t, v, class_A, class_B, mu, lambda_param, C)\n",
    "            h, s, t, c, v = uptade(h, s, t, c, v, step)\n",
    "            ite += 1\n",
    "            bar()\n",
    "\n",
    "    return h, c, s, t, v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long-Step-Method (B4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_step_method(class_A, class_B, lambda_param, nu, epsilon, theta):\n",
    "\n",
    "    h, c, s, t, v, mu = init(class_A, class_B)\n",
    "\n",
    "    nA, n = class_A.vectors.shape\n",
    "    nB = class_B.vectors.shape[0]\n",
    "\n",
    "    C = c_coeff(n, nA, nB, lambda_param)\n",
    "\n",
    "    tau = .25\n",
    "\n",
    "    mu_final = epsilon * (1 - tau) / nu\n",
    "\n",
    "    ite = 0\n",
    "    with alive_bar(10000) as bar:\n",
    "        while mu > mu_final and ite < 10000:\n",
    "            mu *= (1 - theta)\n",
    "            h, s, t, c, v = several_newton(h, c, s, t, v, class_A, class_B, mu, lambda_param, C)\n",
    "            ite += 1\n",
    "            bar()\n",
    "\n",
    "\n",
    "    return h, c, s, t, v\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B3 - B4 (short step / long step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|██▋⚠︎                                    | (!) 66/1000 [7%] in 11.7s (5.64/s) \n",
      "|⚠︎                                       | (!) 5/10000 [0%] in 1:38.3 (0.05/s) \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "NIMAGE = 5 #will be multiplied by 9, can be changed\n",
    "n_pca = 10\n",
    "\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10\n",
    "image_pixels = image_size * image_size\n",
    "data_path = \"./\"\n",
    "train_data = np.loadtxt(data_path + \"mnist_train.csv\", \n",
    "                        delimiter=\",\")\n",
    "test_data = np.loadtxt(data_path + \"mnist_test.csv\", \n",
    "                       delimiter=\",\") \n",
    "\n",
    "fac = 0.99 / 255\n",
    "train_imgs = np.asfarray(train_data[:, 1:]) * fac + 0.01\n",
    "test_imgs = np.asfarray(test_data[:, 1:]) * fac + 0.01\n",
    "\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_labels = np.asfarray(test_data[:, :1])\n",
    "\n",
    "vector_A = train_imgs[np.where(train_labels == 0)[0]]\n",
    "vector_B = np.concatenate([train_imgs[np.where(train_labels == i)[0]][:(NIMAGE)] for i in range(1, 10)])\n",
    "np.random.shuffle(vector_B)\n",
    "vector_A = vector_A[:(NIMAGE*9)]\n",
    "\n",
    "#PCA vectors to fasten the algorithm\n",
    "#vector_A, vector_B = pca(vector_A, vector_B, n_pca)     #uncomment it to use PCA\n",
    "\n",
    "# Initialize class instances\n",
    "class_A = A(vector_A)\n",
    "class_B = B(vector_B)\n",
    "\n",
    "# Set the lambda parameter for the optimization problem\n",
    "lambda_param = 1\n",
    "nu = 2 * len(class_A.vectors) + 2 * len(class_B.vectors) + 2\n",
    "epsilon = 1e-6\n",
    "\n",
    "# h0, c0, s0, t0, v0  = init(class_A, class_B)\n",
    "#h, c, s, t, v  = short_step_method(class_A, class_B, lambda_param, nu, epsilon)   #uncoment for the short-step method\n",
    "\n",
    "# h0, c0, s0, t0, v0  = init(class_A, class_B)\n",
    "h, c, s, t, v  = long_step_method(class_A, class_B, lambda_param, nu, epsilon, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.1 Accuracy over training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_accuracy(imgs, labels, classify, l):\n",
    "    # Accuracy over the training set\n",
    "    y_pred = np.array([classify(im, l) for im in imgs])\n",
    "    labels = (labels > 0)*1.0\n",
    "    print(\"Global Accuracy: \", accuracy_score(labels, y_pred))\n",
    "\n",
    "def label_accuracy(imgs, labels, classify, l):\n",
    "    #Accuracy for each label\n",
    "    for i in range(10):\n",
    "        y_pred = np.array([classify(im, l) for im in imgs[np.where(labels == i)[0]]])\n",
    "        if i > 0: \n",
    "            true = np.ones(y_pred.shape[0])\n",
    "        else:\n",
    "            true = np.zeros(y_pred.shape[0])\n",
    "        print(\"Accuracy for label \"+ str(i) + \": \" + str(accuracy_score(true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|██▋⚠︎                                    | (!) 66/1000 [7%] in 12.8s (5.14/s) \n",
      "|▉⚠︎                                      | (!) 232/10000 [2%] in 41.7s (5.57/s) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m l(x) \u001b[39m<\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m lambda_ \u001b[39min\u001b[39;00m Lambdas:\n\u001b[0;32m----> 8\u001b[0m     h, c, s, t, v \u001b[39m=\u001b[39m short_step_method(class_A, class_B, lambda_, nu, epsilon)\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLambda = \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(lambda_))\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------Global Accuracy Over Training Set in function of Lambda------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36mshort_step_method\u001b[0;34m(class_A, class_B, lambda_param, nu, epsilon)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mwhile\u001b[39;00m mu \u001b[39m>\u001b[39m mu_final \u001b[39mand\u001b[39;00m ite \u001b[39m<\u001b[39m \u001b[39m10000\u001b[39m:\n\u001b[1;32m     18\u001b[0m     mu \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m theta)\n\u001b[0;32m---> 19\u001b[0m     step \u001b[39m=\u001b[39m newton_step(h, c, s, t, v, class_A, class_B, mu, lambda_param, C)\n\u001b[1;32m     20\u001b[0m     h, s, t, c, v \u001b[39m=\u001b[39m uptade(h, s, t, c, v, step)\n\u001b[1;32m     21\u001b[0m     ite \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/HW3_B2.py:79\u001b[0m, in \u001b[0;36mnewton_step\u001b[0;34m(h, c, s, t, v, class_A, class_B, mu, lambda_param, C)\u001b[0m\n\u001b[1;32m     76\u001b[0m n \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39msize\n\u001b[1;32m     78\u001b[0m gradBarrier \u001b[39m=\u001b[39m gradF(h, s, t, c, v, n, nA, nB, A, B)\n\u001b[0;32m---> 79\u001b[0m H \u001b[39m=\u001b[39m hessF(h, s, t, c, v, n, nA, nB, A, B)\n\u001b[1;32m     81\u001b[0m step \u001b[39m=\u001b[39m solve(H, \u001b[39m-\u001b[39m(gradBarrier \u001b[39m+\u001b[39m C\u001b[39m/\u001b[39mmu))\n\u001b[1;32m     82\u001b[0m delta_mu \u001b[39m=\u001b[39m delta(H, step)\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/derivative.py:121\u001b[0m, in \u001b[0;36mhessF\u001b[0;34m(h, s, t, c, v, n, nA, nB, A, B)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhessF\u001b[39m(h, s, t, c, v, n, nA, nB, A, B):\n\u001b[1;32m    120\u001b[0m     hess \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((n \u001b[39m+\u001b[39m nA \u001b[39m+\u001b[39m nB \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m, n \u001b[39m+\u001b[39m nA \u001b[39m+\u001b[39m nB \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[0;32m--> 121\u001b[0m     hess[:n, :n] \u001b[39m=\u001b[39m dFdhh(h, s, t, c, v, n, nA, nB, A, B)\n\u001b[1;32m    122\u001b[0m     hess[:n, n:n\u001b[39m+\u001b[39mnA] \u001b[39m=\u001b[39m dFdhs(h, s, t, c, v, n, nA, nB, A, B)\n\u001b[1;32m    123\u001b[0m     hess[:n, n\u001b[39m+\u001b[39mnA:n\u001b[39m+\u001b[39mnA\u001b[39m+\u001b[39mnB] \u001b[39m=\u001b[39m dFdht(h, s, t, c, v, n, nA, nB, A, B)\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/derivative.py:50\u001b[0m, in \u001b[0;36mdFdhh\u001b[0;34m(h, s, t, c, v, n, nA, nB, A, B)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdFdhh\u001b[39m(h, s, t, c, v, n, nA, nB, A, B):\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39;49m(np\u001b[39m.\u001b[39;49mouter(ai, ai) \u001b[39m/\u001b[39;49m (si \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m c \u001b[39m-\u001b[39;49m np\u001b[39m.\u001b[39;49mdot(ai, h))\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m \u001b[39mfor\u001b[39;49;00m ai, si \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(A, s)) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     51\u001b[0m               \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39mouter(bi, bi) \u001b[39m/\u001b[39m (ti \u001b[39m+\u001b[39m c \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mdot(bi, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m bi, ti \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(B, t)) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     52\u001b[0m                 \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39meye(n)\u001b[39m/\u001b[39m (v \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(h, h)) \u001b[39m+\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mouter(h, h) \u001b[39m/\u001b[39m (v \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(h, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/derivative.py:50\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdFdhh\u001b[39m(h, s, t, c, v, n, nA, nB, A, B):\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39;49mouter(ai, ai) \u001b[39m/\u001b[39m (si \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m c \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(ai, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m ai, si \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(A, s)) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     51\u001b[0m               \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39mouter(bi, bi) \u001b[39m/\u001b[39m (ti \u001b[39m+\u001b[39m c \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mdot(bi, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m bi, ti \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(B, t)) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     52\u001b[0m                 \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39meye(n)\u001b[39m/\u001b[39m (v \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(h, h)) \u001b[39m+\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mouter(h, h) \u001b[39m/\u001b[39m (v \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(h, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mouter\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/numeric.py:936\u001b[0m, in \u001b[0;36mouter\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m    934\u001b[0m a \u001b[39m=\u001b[39m asarray(a)\n\u001b[1;32m    935\u001b[0m b \u001b[39m=\u001b[39m asarray(b)\n\u001b[0;32m--> 936\u001b[0m \u001b[39mreturn\u001b[39;00m multiply(a\u001b[39m.\u001b[39;49mravel()[:, newaxis], b\u001b[39m.\u001b[39;49mravel()[newaxis, :], out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Lambdas = [0.1, 1, 10, 100, 1000]\n",
    "Thetas = [0.1, 0.5, 0.9, 0.99]\n",
    "l = lambda x: np.dot(h, x) + c\n",
    "def classify(x, l=l):\n",
    "    return 0 if l(x) < -1 else 1\n",
    "\n",
    "for lambda_ in Lambdas:\n",
    "    h, c, s, t, v = short_step_method(class_A, class_B, lambda_, nu, epsilon)\n",
    "    \n",
    "    print(\"Lambda = \" + str(lambda_))\n",
    "    print(\"-------------Global Accuracy Over Training Set in function of Lambda------------------------\")\n",
    "    global_accuracy(train_imgs, classify, l)\n",
    "    print(\"-------------Accuracy for each label Over Training Set in function of Lambda----------------\")\n",
    "    label_accuracy(train_imgs, train_labels, classify, l)\n",
    "\n",
    "for theta in Thetas:\n",
    "    h, c, s, t, v = long_step_method(class_A, class_B, lambda_param, nu, epsilon, theta)\n",
    "    \n",
    "    print(\"Theta = \" + str(theta))\n",
    "    print(\"-------------Global Accuracy Over Training Set in function of Theta------------------------\")\n",
    "    global_accuracy(train_imgs, classify, l)\n",
    "    print(\"-------------Accuracy for each label Over Training Set in function of Theta----------------\")\n",
    "    label_accuracy(train_imgs, train_labels, classify, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.2 Generalized Performance (accuracy over test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|██▍⚠︎                                    | (!) 59/1000 [6%] in 12.3s (4.80/s) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m h, c, s, t, v  \u001b[39m=\u001b[39m long_step_method(class_A, class_B, lambda_param, nu, epsilon, \u001b[39m0.99\u001b[39;49m) \u001b[39m#To change for the best method, could be long-step or short step\u001b[39;00m\n\u001b[1;32m      2\u001b[0m l \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mdot(h, x) \u001b[39m+\u001b[39m c\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------Global Accuracy Over Test Set------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mlong_step_method\u001b[0;34m(class_A, class_B, lambda_param, nu, epsilon, theta)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlong_step_method\u001b[39m(class_A, class_B, lambda_param, nu, epsilon, theta):\n\u001b[0;32m----> 3\u001b[0m     h, c, s, t, v, mu \u001b[39m=\u001b[39m init(class_A, class_B)\n\u001b[1;32m      5\u001b[0m     nA, n \u001b[39m=\u001b[39m class_A\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape\n\u001b[1;32m      6\u001b[0m     nB \u001b[39m=\u001b[39m class_B\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/HW3_B2.py:111\u001b[0m, in \u001b[0;36minit\u001b[0;34m(class_A, class_B)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m alive_bar(\u001b[39m1000\u001b[39m) \u001b[39mas\u001b[39;00m bar:\n\u001b[1;32m    109\u001b[0m     \u001b[39mwhile\u001b[39;00m (delta(H, step) \u001b[39m>\u001b[39m \u001b[39m.25\u001b[39m \u001b[39mand\u001b[39;00m ite \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m         step \u001b[39m=\u001b[39m newton_step(h, c, s, t, v, class_A, class_B, mu, lambda_param, C)\n\u001b[1;32m    112\u001b[0m         h, s, t, c, v \u001b[39m=\u001b[39m uptade(h, s, t, c, v, step)\n\u001b[1;32m    114\u001b[0m         grad \u001b[39m=\u001b[39m C\u001b[39m/\u001b[39mmu \u001b[39m+\u001b[39m  gradF(h, s, t, c, v, n, nA, nB, class_A\u001b[39m.\u001b[39mvectors, class_B\u001b[39m.\u001b[39mvectors)\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/HW3_B2.py:79\u001b[0m, in \u001b[0;36mnewton_step\u001b[0;34m(h, c, s, t, v, class_A, class_B, mu, lambda_param, C)\u001b[0m\n\u001b[1;32m     76\u001b[0m n \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39msize\n\u001b[1;32m     78\u001b[0m gradBarrier \u001b[39m=\u001b[39m gradF(h, s, t, c, v, n, nA, nB, A, B)\n\u001b[0;32m---> 79\u001b[0m H \u001b[39m=\u001b[39m hessF(h, s, t, c, v, n, nA, nB, A, B)\n\u001b[1;32m     81\u001b[0m step \u001b[39m=\u001b[39m solve(H, \u001b[39m-\u001b[39m(gradBarrier \u001b[39m+\u001b[39m C\u001b[39m/\u001b[39mmu))\n\u001b[1;32m     82\u001b[0m delta_mu \u001b[39m=\u001b[39m delta(H, step)\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/derivative.py:121\u001b[0m, in \u001b[0;36mhessF\u001b[0;34m(h, s, t, c, v, n, nA, nB, A, B)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhessF\u001b[39m(h, s, t, c, v, n, nA, nB, A, B):\n\u001b[1;32m    120\u001b[0m     hess \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((n \u001b[39m+\u001b[39m nA \u001b[39m+\u001b[39m nB \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m, n \u001b[39m+\u001b[39m nA \u001b[39m+\u001b[39m nB \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[0;32m--> 121\u001b[0m     hess[:n, :n] \u001b[39m=\u001b[39m dFdhh(h, s, t, c, v, n, nA, nB, A, B)\n\u001b[1;32m    122\u001b[0m     hess[:n, n:n\u001b[39m+\u001b[39mnA] \u001b[39m=\u001b[39m dFdhs(h, s, t, c, v, n, nA, nB, A, B)\n\u001b[1;32m    123\u001b[0m     hess[:n, n\u001b[39m+\u001b[39mnA:n\u001b[39m+\u001b[39mnA\u001b[39m+\u001b[39mnB] \u001b[39m=\u001b[39m dFdht(h, s, t, c, v, n, nA, nB, A, B)\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/derivative.py:50\u001b[0m, in \u001b[0;36mdFdhh\u001b[0;34m(h, s, t, c, v, n, nA, nB, A, B)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdFdhh\u001b[39m(h, s, t, c, v, n, nA, nB, A, B):\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39;49m(np\u001b[39m.\u001b[39;49mouter(ai, ai) \u001b[39m/\u001b[39;49m (si \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m c \u001b[39m-\u001b[39;49m np\u001b[39m.\u001b[39;49mdot(ai, h))\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m \u001b[39mfor\u001b[39;49;00m ai, si \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(A, s)) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     51\u001b[0m               \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39mouter(bi, bi) \u001b[39m/\u001b[39m (ti \u001b[39m+\u001b[39m c \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mdot(bi, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m bi, ti \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(B, t)) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     52\u001b[0m                 \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39meye(n)\u001b[39m/\u001b[39m (v \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(h, h)) \u001b[39m+\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mouter(h, h) \u001b[39m/\u001b[39m (v \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(h, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Optimization II/hw3/derivative.py:50\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdFdhh\u001b[39m(h, s, t, c, v, n, nA, nB, A, B):\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39mouter(ai, ai) \u001b[39m/\u001b[39m (si \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m c \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(ai, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m ai, si \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(A, s)) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     51\u001b[0m               \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39mouter(bi, bi) \u001b[39m/\u001b[39m (ti \u001b[39m+\u001b[39m c \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mdot(bi, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m bi, ti \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(B, t)) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     52\u001b[0m                 \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39meye(n)\u001b[39m/\u001b[39m (v \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(h, h)) \u001b[39m+\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mouter(h, h) \u001b[39m/\u001b[39m (v \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(h, h))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h, c, s, t, v  = long_step_method(class_A, class_B, lambda_param, nu, epsilon, 0.99) #To change for the best method, could be long-step or short step\n",
    "l = lambda x: np.dot(h, x) + c\n",
    "\n",
    "print(\"-------------Global Accuracy Over Test Set------------------------\")\n",
    "global_accuracy(test_imgs, test_labels, classify, l)\n",
    "print(\"-------------Accuracy for each label Over Test Set----------------\")\n",
    "label_accuracy(test_imgs, test_labels, classify, l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ed289b8c0ef30bdfd3a798f8985acef2eef128f2ad4f00beb79a4ac60eddab9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
